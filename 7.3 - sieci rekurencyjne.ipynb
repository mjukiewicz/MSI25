{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d385895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "n_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=n_words)\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "\n",
    "EPOCHS = 1000\n",
    "\n",
    "#https://keras.io/api/datasets/imdb/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2674d279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyświetl pierwszy element zbioru X_train\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0a6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wyświetl pierwszy element zbioru y_train\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4908a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ta komórka słuzy dopełeniu ciągów wyrazów. Sieć ma stałą wielkość pierwszej warstwy. Zadania nie mają stałej \n",
    "#długości. Dlatego, każde zdanie, które będzie miało mniej niż 100 wyrazów dopełniamy zerami.\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 100\n",
    "\n",
    "X_train_pad = pad_sequences(X_train, maxlen=max_words, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test, maxlen=max_words, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f44f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kluczowa jest tu warstwa Embedding, w której ustawiamy wielkość słownika, w ilu wymiarach chcemy umieścić słowa \n",
    "#Na koniec ustawiamy jak długie są zdania, my ustaliliśmy, że mają 100 wyrazów.\n",
    "#\"Warstwa Embedding przekształca wejściowe liczby całkowite na wektory o \n",
    "#określonym wymiarze. Jest to zasadniczo macierz, gdzie każdy wiersz odpowiada wektorowi \n",
    "#osadzenia danego indeksu.\"\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Embedding, Flatten\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = n_words, output_dim = 16, input_length = max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_pad,y_train, epochs = EPOCHS, validation_data = (X_test_pad,y_test), callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c38071",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist.loss, label = \"loss\")\n",
    "plt.plot(hist.val_loss, label = \"val_loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist.accuracy, label = \"acc\")\n",
    "plt.plot(hist.val_accuracy, label = \"val_acc\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d92090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
