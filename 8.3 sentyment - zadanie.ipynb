{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0dd96726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 17:32:06.352359: E itex/core/kernels/xpu_kernel.cc:38] XPU-GPU kernel not supported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"-1\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)\n",
    "\n",
    "EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e667796f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/usr/share/MSI25/IMDB Dataset.csv', sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbfc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from tqdm import tqdm\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abee84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = []\n",
    "\n",
    "# Storing all punctuations using RE library like !;,\"% etc\n",
    "re_puncs = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "# Storing all stop words like a, an, the, when, there, this etc\n",
    "stop_word  = set(stopwords.words('english'))\n",
    "stop_word.add(\"im\")\n",
    "# print(stop_word)\n",
    "# Making Lemmatizing object\n",
    "lem = WordNetLemmatizer()\n",
    "# Using Porter Stemmer\n",
    "p_stem = PorterStemmer()\n",
    "\n",
    "# Traversing whole dataset\n",
    "for i in tqdm(range(len(df['review']))):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(str(df['review'][i]))\n",
    "    # Converting all characters to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # Remove all punctuations from sentenses\n",
    "    tokens = [re_puncs.sub('', w) for w in tokens]\n",
    "    # Checking all words is alphabets or not\n",
    "    tokens = [i for i in tokens if i.isalpha()]\n",
    "    # Removing all stop words from the sentenses\n",
    "    tokens = [w for w in tokens if w not in stop_word]\n",
    "    # Doing Lemmatizing of words\n",
    "    tokens = [lem.lemmatize(w) for w in tokens]\n",
    "    # Stemming process\n",
    "    tokens = [p_stem.stem(w) for w in tokens]\n",
    "    # Finally convert to string\n",
    "    r = ' '.join(tokens)\n",
    "    # Storing the final string into main list\n",
    "    main.append(r)\n",
    "    \n",
    "#https://www.kaggle.com/code/tanujdhiman/twitter-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf001c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['translated'] = main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 50000, oov_token = \"<00V>\")\n",
    "tokenizer.fit_on_texts(df['translated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22a3a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "df['sentiment_cat']=label_encoder.fit_transform(df['sentiment'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"translated\"], df['sentiment_cat'], train_size = 0.8, random_state=1)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train, maxlen=50, padding=\"post\")\n",
    "X_test_pad = pad_sequences(X_test, maxlen=50, padding=\"post\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64218758",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Porównaj ze sobą modele wykorzystujące SimpleRNN, GRU i LSTM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
